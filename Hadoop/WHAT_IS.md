## 아파치 스파크

- 오픈소스 분산 쿼리 및 처리 엔진
- 유연성 & 빠른 속도(맵리듀스에 대한 확장성)
- 데이터를 읽고 변형, 합계, 복잡한 통계모델을 쉽게 학습 및 배포 가능
- 자바, 스칼라, 파이썬, R, SQL 등으로 접근 가능

- 하둡 : 분산 저장을 하더라고 결국 스토리지에 세이브  
  => 이 때 RAM이 놀게 되는데, 이를 사용한 것이 아파치 스파크


- 빠른 성능을 위해 인메모리 캐싱과 최적화된 실행을 사용
- 일반 배치처리 스트리밍 분석, 머신러닝, 그래프, 데이터베이스 및 임시 쿼리를 지원








~~~
pyspark

>>> print("asd")
asd
>>> nums = sc.parallelize([1,2,3,4])
>>> nums.map(lambda  x:x*x).collect()
[1, 4, 9, 16]
~~~

- 모듈 설치

~~~
conda install -c conda-forge findspark 
~~~




